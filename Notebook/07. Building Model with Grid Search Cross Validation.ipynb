{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Random Forest with Grid Search \n",
    "\n",
    "**Grid Search** : Exhaustively Search All Parameter `Combinations` in a given `Grid` to Determine Best Model.\n",
    "\n",
    "**Cross Validation** : Divide a Data Set into `K` Subsets, Keep One Set for Test and Validation and use rest `K - 1` for Training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `Libraries` and `Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  I've been searching for the right words to tha...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3   ham  Even my brother is not like to speak with me. ...\n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import string\n",
    "\n",
    "df = pd.read_csv('../Data/SMSSpamCollection.tsv', \n",
    "                 sep='\\t', \n",
    "                 header=None, \n",
    "                 names=['Label','SMS'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>SMS_Length</th>\n",
       "      <th>Punctuation%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  SMS_Length  \\\n",
       "0   ham  I've been searching for the right words to tha...         160   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...         128   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...          49   \n",
       "3   ham  Even my brother is not like to speak with me. ...          62   \n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!          28   \n",
       "\n",
       "   Punctuation%  \n",
       "0           2.5  \n",
       "1           4.7  \n",
       "2           4.1  \n",
       "3           3.2  \n",
       "4           7.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_punctuation(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation]) \n",
    "    return round(count/(len(text) - text.count(' ')),3)*100 # Excluding Whitespace\n",
    "\n",
    "df['SMS_Length'] = df['SMS'].apply(lambda x : len(x) - x.count(' ')) # Excluding Whitespace\n",
    "df['Punctuation%'] = df['SMS'].apply(lambda x : count_punctuation(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Clean` Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    no_punctuation = ''.join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    stems = [ps.stem(word) for word in tokens if word not in stopwords] # Remove Stopwords\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `Vectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS_Length</th>\n",
       "      <th>Punctuation%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>7521</th>\n",
       "      <th>7522</th>\n",
       "      <th>7523</th>\n",
       "      <th>7524</th>\n",
       "      <th>7525</th>\n",
       "      <th>7526</th>\n",
       "      <th>7527</th>\n",
       "      <th>7528</th>\n",
       "      <th>7529</th>\n",
       "      <th>7530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.053151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.074069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.092792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7533 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SMS_Length  Punctuation%         0    1    2    3    4    5    6    7  ...  \\\n",
       "0         160           2.5  0.053151  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1         128           4.7  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2          49           4.1  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3          62           3.2  0.074069  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4          28           7.1  0.092792  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "   7521  7522  7523  7524  7525  7526  7527  7528  7529  7530  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 7533 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vector = tfidf.fit_transform(df['SMS'])\n",
    "\n",
    "tfidf_vector_df = pd.DataFrame(tfidf_vector.toarray())\n",
    "\n",
    "# Create Feature\n",
    "X = pd.concat([df['SMS_Length'], df['Punctuation%'], tfidf_vector_df], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer=clean_text)\n",
    "count_vector = cv.fit_transform(df['SMS'])\n",
    "count_vector_df = pd.DataFrame(count_vector.toarray())\n",
    "\n",
    "count_vector_X = pd.concat([df['SMS_Length'], df['Punctuation%'], count_vector_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `Random Forest Classifier` and `Grid Search Cross Validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `GridSearchCV` for TfidfVectorizer\n",
    "\n",
    "- This will Take Time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31.364583</td>\n",
       "      <td>1.203654</td>\n",
       "      <td>0.529935</td>\n",
       "      <td>0.083440</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.982944</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.980234</td>\n",
       "      <td>0.979525</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.112007</td>\n",
       "      <td>0.937949</td>\n",
       "      <td>0.405040</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.981149</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.980234</td>\n",
       "      <td>0.978807</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.148477</td>\n",
       "      <td>1.534237</td>\n",
       "      <td>0.734091</td>\n",
       "      <td>0.378924</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.981149</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.979335</td>\n",
       "      <td>0.978268</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>57.213691</td>\n",
       "      <td>0.579770</td>\n",
       "      <td>0.745575</td>\n",
       "      <td>0.138066</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.981149</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.978268</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>47.065308</td>\n",
       "      <td>1.319971</td>\n",
       "      <td>0.382482</td>\n",
       "      <td>0.127378</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.981149</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.979335</td>\n",
       "      <td>0.978268</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7       31.364583      1.203654         0.529935        0.083440   \n",
       "4       25.112007      0.937949         0.405040        0.026826   \n",
       "5       50.148477      1.534237         0.734091        0.378924   \n",
       "8       57.213691      0.579770         0.745575        0.138066   \n",
       "11      47.065308      1.319971         0.382482        0.127378   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "7               90                150   \n",
       "4               60                150   \n",
       "5               60                300   \n",
       "8               90                300   \n",
       "11            None                300   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.980251   \n",
       "4     {'max_depth': 60, 'n_estimators': 150}           0.981149   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}           0.978456   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.978456   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.980251   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.982944           0.979354           0.974843   \n",
       "4            0.980251           0.978456           0.973944   \n",
       "5            0.981149           0.977558           0.974843   \n",
       "8            0.981149           0.977558           0.973046   \n",
       "11           0.981149           0.977558           0.973046   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7            0.980234         0.979525        0.002633                1  \n",
       "4            0.980234         0.978807        0.002584                2  \n",
       "5            0.979335         0.978268        0.002084                3  \n",
       "8            0.981132         0.978268        0.002977                3  \n",
       "11           0.979335         0.978268        0.002869                5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "param = {'n_estimators':[10,150,300],\n",
    "         'max_depth':[30,60,90,None]}\n",
    "\n",
    "gscv = GridSearchCV(rfc, param, cv=5, n_jobs=-1)\n",
    "model = gscv.fit(X, df['Label'])\n",
    "pd.DataFrame(model.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `GridSearchCV` for CountVectorizer\n",
    "\n",
    "- This will also take Time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35.828316</td>\n",
       "      <td>1.586597</td>\n",
       "      <td>0.657436</td>\n",
       "      <td>0.245385</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.980234</td>\n",
       "      <td>0.978628</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.656874</td>\n",
       "      <td>0.566591</td>\n",
       "      <td>0.291212</td>\n",
       "      <td>0.047264</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 10}</td>\n",
       "      <td>0.983842</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.979335</td>\n",
       "      <td>0.977909</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59.747466</td>\n",
       "      <td>1.224805</td>\n",
       "      <td>0.921097</td>\n",
       "      <td>0.204344</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.977909</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.451645</td>\n",
       "      <td>1.567487</td>\n",
       "      <td>0.421130</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.976640</td>\n",
       "      <td>0.980234</td>\n",
       "      <td>0.977551</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.634946</td>\n",
       "      <td>1.174259</td>\n",
       "      <td>0.945907</td>\n",
       "      <td>0.059403</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.980234</td>\n",
       "      <td>0.977371</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7      35.828316      1.586597         0.657436        0.245385   \n",
       "3       4.656874      0.566591         0.291212        0.047264   \n",
       "8      59.747466      1.224805         0.921097        0.204344   \n",
       "4      27.451645      1.567487         0.421130        0.044818   \n",
       "5      55.634946      1.174259         0.945907        0.059403   \n",
       "\n",
       "  param_max_depth param_n_estimators                                  params  \\\n",
       "7              90                150  {'max_depth': 90, 'n_estimators': 150}   \n",
       "3              60                 10   {'max_depth': 60, 'n_estimators': 10}   \n",
       "8              90                300  {'max_depth': 90, 'n_estimators': 300}   \n",
       "4              60                150  {'max_depth': 60, 'n_estimators': 150}   \n",
       "5              60                300  {'max_depth': 60, 'n_estimators': 300}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7           0.978456           0.980251           0.978456           0.975741   \n",
       "3           0.983842           0.976661           0.973968           0.975741   \n",
       "8           0.979354           0.977558           0.977558           0.973944   \n",
       "4           0.979354           0.978456           0.973070           0.976640   \n",
       "5           0.979354           0.977558           0.975763           0.973944   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7           0.980234         0.978628        0.001650                1  \n",
       "3           0.979335         0.977909        0.003436                2  \n",
       "8           0.981132         0.977909        0.002385                2  \n",
       "4           0.980234         0.977551        0.002537                4  \n",
       "5           0.980234         0.977371        0.002302                5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "param = {'n_estimators':[10,150,300],\n",
    "         'max_depth':[30,60,90,None]}\n",
    "\n",
    "gscv = GridSearchCV(rfc, param, cv=5, n_jobs=-1)\n",
    "model = gscv.fit(count_vector_X, df['Label'])\n",
    "pd.DataFrame(model.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
