{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Method\n",
    "\n",
    "Create Multiple Models and then combine them to Produce **Better** Results that any Single Model **Individually**.\n",
    "\n",
    "### Gradient Boosting\n",
    "An **Iterative** Approach\n",
    "\n",
    "**Combine** Weak Learners to Create a **Strong** Learner by Focusing on Mistakes of Prior Iterations.\n",
    "\n",
    "### Explore Gradient Boosting with Grid Search \n",
    "\n",
    "**Grid Search** : Exhaustively Search All Parameter `Combinations` in a given `Grid` to Determine Best Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `Libraries` and `Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  I've been searching for the right words to tha...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3   ham  Even my brother is not like to speak with me. ...\n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "\n",
    "df = pd.read_csv('../Data/SMSSpamCollection.tsv', sep='\\t', header=None, names=['Label','SMS'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>SMS_Length</th>\n",
       "      <th>Punctuation%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  SMS_Length  \\\n",
       "0   ham  I've been searching for the right words to tha...         160   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...         128   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...          49   \n",
       "3   ham  Even my brother is not like to speak with me. ...          62   \n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!          28   \n",
       "\n",
       "   Punctuation%  \n",
       "0           2.5  \n",
       "1           4.7  \n",
       "2           4.1  \n",
       "3           3.2  \n",
       "4           7.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_punctuation(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation]) \n",
    "    return round(count/(len(text) - text.count(' ')),3)*100 # Excluding Whitespace\n",
    "\n",
    "df['SMS_Length'] = df['SMS'].apply(lambda x : len(x) - x.count(' ')) # Excluding Whitespace\n",
    "df['Punctuation%'] = df['SMS'].apply(lambda x : count_punctuation(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Clean` Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    no_punctuation = ''.join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    stems = [ps.stem(word) for word in tokens if word not in stopwords] # Remove Stopwords\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `Vectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS_Length</th>\n",
       "      <th>Punctuation%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>7521</th>\n",
       "      <th>7522</th>\n",
       "      <th>7523</th>\n",
       "      <th>7524</th>\n",
       "      <th>7525</th>\n",
       "      <th>7526</th>\n",
       "      <th>7527</th>\n",
       "      <th>7528</th>\n",
       "      <th>7529</th>\n",
       "      <th>7530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.053151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.074069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.092792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7533 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SMS_Length  Punctuation%         0    1    2    3    4    5    6    7  ...  \\\n",
       "0         160           2.5  0.053151  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1         128           4.7  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2          49           4.1  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3          62           3.2  0.074069  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4          28           7.1  0.092792  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "   7521  7522  7523  7524  7525  7526  7527  7528  7529  7530  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 7533 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vector = tfidf.fit_transform(df['SMS'])\n",
    "\n",
    "tfidf_vector_df = pd.DataFrame(tfidf_vector.toarray())\n",
    "\n",
    "# Create Feature\n",
    "X = pd.concat([df['SMS_Length'], df['Punctuation%'], tfidf_vector_df], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Split` the Data into `Train` and `Test` Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_SUPPORTED_LOSS', '__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_check_initialized', '_check_n_features', '_check_params', '_clear_state', '_compute_partial_dependence_recursion', '_estimator_type', '_fit_stage', '_fit_stages', '_get_param_names', '_get_tags', '_init_state', '_is_initialized', '_make_estimator', '_more_tags', '_raw_predict', '_raw_predict_init', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_required_parameters', '_resize_state', '_staged_raw_predict', '_validate_data', '_validate_estimator', '_validate_y', 'apply', 'decision_function', 'feature_importances_', 'fit', 'get_params', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params', 'staged_decision_function', 'staged_predict', 'staged_predict_proba']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "print(dir(GradientBoostingClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    df['Label'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build `Grid Search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GB(n_estimator, max_depth, learning_rate):\n",
    "    gb = GradientBoostingClassifier(n_estimators=n_estimator, \n",
    "                                    max_depth=max_depth, \n",
    "                                    learning_rate=learning_rate)\n",
    "    model = gb.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, \n",
    "                                               y_pred, \n",
    "                                               pos_label='spam', \n",
    "                                               average='binary')\n",
    "    \n",
    "    print(f'Estimator : {n_estimator} | Depth : {max_depth} | Precision : {precision*100:.2f}% | Recall : {recall*100:.2f}% | Accuracy : {((y_pred==y_test).sum() / len(y_pred))*100:.2f}%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirankumar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator : 50 | Depth : 3 | Precision : 0.00% | Recall : 0.00% | Accuracy : 86.62%\n",
      "Estimator : 50 | Depth : 3 | Precision : 97.27% | Recall : 71.81% | Accuracy : 95.96%\n",
      "Estimator : 50 | Depth : 3 | Precision : 91.79% | Recall : 82.55% | Accuracy : 96.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirankumar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator : 50 | Depth : 7 | Precision : 0.00% | Recall : 0.00% | Accuracy : 86.62%\n",
      "Estimator : 50 | Depth : 7 | Precision : 93.38% | Recall : 85.23% | Accuracy : 97.22%\n",
      "Estimator : 50 | Depth : 7 | Precision : 89.13% | Recall : 82.55% | Accuracy : 96.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirankumar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator : 50 | Depth : 11 | Precision : 0.00% | Recall : 0.00% | Accuracy : 86.62%\n",
      "Estimator : 50 | Depth : 11 | Precision : 92.81% | Recall : 86.58% | Accuracy : 97.31%\n",
      "Estimator : 50 | Depth : 11 | Precision : 92.48% | Recall : 82.55% | Accuracy : 96.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirankumar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator : 50 | Depth : 15 | Precision : 0.00% | Recall : 0.00% | Accuracy : 86.62%\n",
      "Estimator : 50 | Depth : 15 | Precision : 93.53% | Recall : 87.25% | Accuracy : 97.49%\n",
      "Estimator : 50 | Depth : 15 | Precision : 93.48% | Recall : 86.58% | Accuracy : 97.40%\n",
      "Estimator : 100 | Depth : 3 | Precision : 97.30% | Recall : 48.32% | Accuracy : 92.91%\n",
      "Estimator : 100 | Depth : 3 | Precision : 95.93% | Recall : 79.19% | Accuracy : 96.77%\n",
      "Estimator : 100 | Depth : 3 | Precision : 91.11% | Recall : 82.55% | Accuracy : 96.59%\n",
      "Estimator : 100 | Depth : 7 | Precision : 97.12% | Recall : 67.79% | Accuracy : 95.42%\n",
      "Estimator : 100 | Depth : 7 | Precision : 94.78% | Recall : 85.23% | Accuracy : 97.40%\n",
      "Estimator : 100 | Depth : 7 | Precision : 87.77% | Recall : 81.88% | Accuracy : 96.05%\n",
      "Estimator : 100 | Depth : 11 | Precision : 94.17% | Recall : 75.84% | Accuracy : 96.14%\n",
      "Estimator : 100 | Depth : 11 | Precision : 92.86% | Recall : 87.25% | Accuracy : 97.40%\n",
      "Estimator : 100 | Depth : 11 | Precision : 94.03% | Recall : 84.56% | Accuracy : 97.22%\n",
      "Estimator : 100 | Depth : 15 | Precision : 93.39% | Recall : 75.84% | Accuracy : 96.05%\n",
      "Estimator : 100 | Depth : 15 | Precision : 93.48% | Recall : 86.58% | Accuracy : 97.40%\n",
      "Estimator : 100 | Depth : 15 | Precision : 94.93% | Recall : 87.92% | Accuracy : 97.76%\n",
      "Estimator : 150 | Depth : 3 | Precision : 97.44% | Recall : 51.01% | Accuracy : 93.27%\n",
      "Estimator : 150 | Depth : 3 | Precision : 96.85% | Recall : 82.55% | Accuracy : 97.31%\n",
      "Estimator : 150 | Depth : 3 | Precision : 92.59% | Recall : 83.89% | Accuracy : 96.95%\n",
      "Estimator : 150 | Depth : 7 | Precision : 95.65% | Recall : 73.83% | Accuracy : 96.05%\n",
      "Estimator : 150 | Depth : 7 | Precision : 95.56% | Recall : 86.58% | Accuracy : 97.67%\n",
      "Estimator : 150 | Depth : 7 | Precision : 89.13% | Recall : 82.55% | Accuracy : 96.32%\n",
      "Estimator : 150 | Depth : 11 | Precision : 94.31% | Recall : 77.85% | Accuracy : 96.41%\n",
      "Estimator : 150 | Depth : 11 | Precision : 93.48% | Recall : 86.58% | Accuracy : 97.40%\n",
      "Estimator : 150 | Depth : 11 | Precision : 94.85% | Recall : 86.58% | Accuracy : 97.58%\n",
      "Estimator : 150 | Depth : 15 | Precision : 94.21% | Recall : 76.51% | Accuracy : 96.23%\n",
      "Estimator : 150 | Depth : 15 | Precision : 93.57% | Recall : 87.92% | Accuracy : 97.58%\n",
      "Estimator : 150 | Depth : 15 | Precision : 95.65% | Recall : 88.59% | Accuracy : 97.94%\n"
     ]
    }
   ],
   "source": [
    "for n_estimator in [50,100,150]:\n",
    "    for max_depth in [3,7,11,15]:\n",
    "        for learning_rate in [0.01,0.1,1]:\n",
    "            train_GB(n_estimator,max_depth,learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
